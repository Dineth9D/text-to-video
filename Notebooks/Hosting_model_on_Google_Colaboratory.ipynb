{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hef_Pp6nW0Wk"
      },
      "outputs": [],
      "source": [
        "!pip install transformers fastapi uvicorn pyngrok accelerate diffusers imageio-ffmpeg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H3joEiIduEOF"
      },
      "outputs": [],
      "source": [
        "!ngrok config add-authtoken <your-ngroktoken> # Add your ngrok token here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NJCj4qvempWx"
      },
      "outputs": [],
      "source": [
        "from fastapi import FastAPI, HTTPException\n",
        "from fastapi.responses import FileResponse\n",
        "from pydantic import BaseModel\n",
        "from diffusers import DiffusionPipeline, I2VGenXLPipeline\n",
        "from diffusers.utils import export_to_video, load_image\n",
        "\n",
        "\n",
        "from pyngrok import ngrok\n",
        "import uvicorn\n",
        "import nest_asyncio\n",
        "import torch\n",
        "import uuid\n",
        "import base64\n",
        "import requests\n",
        "from PIL import Image\n",
        "from io import BytesIO\n",
        "\n",
        "app = FastAPI()\n",
        "\n",
        "text_to_video_pipeline = DiffusionPipeline.from_pretrained(\"damo-vilab/text-to-video-ms-1.7b\", torch_dtype=torch.float16, variant=\"fp16\")\n",
        "text_to_video_pipeline.enable_model_cpu_offload()\n",
        "text_to_video_pipeline.enable_vae_slicing()\n",
        "\n",
        "image_to_video_pipeline = I2VGenXLPipeline.from_pretrained(\"ali-vilab/i2vgen-xl\", torch_dtype=torch.float16, variant=\"fp16\")\n",
        "image_to_video_pipeline.enable_model_cpu_offload()\n",
        "image_to_video_pipeline.enable_sequential_cpu_offload()\n",
        "image_to_video_pipeline.vae.enable_slicing()\n",
        "image_to_video_pipeline.vae.enable_tiling()\n",
        "\n",
        "processed_requests = {}\n",
        "\n",
        "\n",
        "class Prompt(BaseModel):\n",
        "    text: str = None\n",
        "    image: str = None\n",
        "    request_id: str\n",
        "\n",
        "\n",
        "@app.get(\"/\")\n",
        "def root():\n",
        "    return {\"message\": \"FastAPI server for video generation inference is running!\"}\n",
        "\n",
        "\n",
        "@app.post(\"/predict/\")\n",
        "def predict(request: Prompt):\n",
        "    try:\n",
        "        print(f\"Received payload: {request.dict()}\")\n",
        "\n",
        "        request_id = request.request_id\n",
        "        prompt_text = request.text or \"\"\n",
        "        image_base64 = request.image\n",
        "\n",
        "        if not prompt_text and not image_base64:\n",
        "            raise HTTPException(\n",
        "                status_code=400, detail=\"At least one of 'text' or 'image_base64' must be provided.\"\n",
        "            )\n",
        "\n",
        "\n",
        "        if request_id in processed_requests:\n",
        "            video_filename = processed_requests[request_id]\n",
        "            return FileResponse(video_filename, media_type=\"video/mp4\", filename=video_filename)\n",
        "\n",
        "        video_id = str(uuid.uuid4())\n",
        "        video_filename = f\"{video_id}.mp4\"\n",
        "\n",
        "        negative_prompt = \"Distorted, discontinuous, Ugly, blurry, low resolution, motionless, static, disfigured, disconnected limbs, Ugly faces, incomplete arms\"\n",
        "\n",
        "        if prompt_text and image_base64:\n",
        "            image_bytes = base64.b64decode(image_base64)\n",
        "            image = Image.open(BytesIO(image_bytes)).convert(\"RGB\")\n",
        "            video = image_to_video_pipeline(\n",
        "                prompt=prompt_text,\n",
        "                image=image,\n",
        "                num_inference_steps=50,\n",
        "                negative_prompt=negative_prompt,\n",
        "                guidance_scale=9.0,\n",
        "                generator=torch.Generator(device=\"cuda\").manual_seed(8888),\n",
        "            ).frames[0]\n",
        "\n",
        "        elif prompt_text:\n",
        "            video = text_to_video_pipeline(prompt_text).frames[0]\n",
        "\n",
        "        elif image_base64:\n",
        "            image_bytes = base64.b64decode(image_base64)\n",
        "            image = Image.open(BytesIO(image_bytes)).convert(\"RGB\")\n",
        "            video = image_to_video_pipeline(\n",
        "                prompt=\"\",\n",
        "                image=image,\n",
        "                num_inference_steps=50,\n",
        "                negative_prompt=negative_prompt,\n",
        "                guidance_scale=9.0,\n",
        "                generator=torch.Generator(device=\"cuda\").manual_seed(8888),\n",
        "            ).frames[0]\n",
        "\n",
        "        export_to_video(video, video_filename, fps=10)\n",
        "        processed_requests[request_id] = video_filename\n",
        "\n",
        "        return FileResponse(video_filename, media_type=\"video/mp4\", filename=video_filename)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error: {e}\")\n",
        "        raise HTTPException(status_code=500, detail=f\"Error: {str(e)}\")\n",
        "\n",
        "\n",
        "def start_ngrok():\n",
        "    public_url = ngrok.connect(8000)\n",
        "    print(f\"Public URL: {public_url}\")\n",
        "\n",
        "def start_server():\n",
        "    nest_asyncio.apply()\n",
        "    uvicorn.run(app, host=\"0.0.0.0\", port=8000)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"Starting ngrok...\")\n",
        "    start_ngrok()\n",
        "    print(\"Starting FastAPI server...\")\n",
        "    start_server()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
